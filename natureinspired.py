# -*- coding: utf-8 -*-
"""natureinspired.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lisdWish7JWOi1w3eoQnGIyn8LBy9-Xe

https://github.com/jonasgrebe/bees-bats-fireflies
"""

import numpy as np
import matplotlib.pyplot as plt

from time import perf_counter, process_time
import imageio
import os

class BaseSearchAlgorithm():
    
    def __init__(self, name, **kwargs):
        print(name, kwargs)
        self.name = name
        self.objective = None
        self.objective_fct = None

        self.solutions = []
        self.history = []
        self.best_solution = None
        self.params = kwargs

        self.n = self.params['n'] # size of population
        self.d = self.params['d'] # dimensionality of solution space
        
        self.range_min = self.params['range_min'] # lower bound in all dimensions
        self.range_max = self.params['range_max'] # upper bound in all dimensions
        
        if np.isscalar(self.range_min):
            self.range_min = np.repeat(self.range_min, self.d)
            
        if np.isscalar(self.range_max):
            self.range_max = np.repeat(self.range_max, self.d)
            
        self.evaluation_count = 0
            
        
    def constraints_satisfied(self):
        return True
    

    def get_best_solution(self, key=None):
        if not key:
            key = self.objective_fct
        
        if self.objective == 'min':
            candidate = min(self.solutions, key=key)
        elif self.objective == 'max':
            candidate = max(self.solutions, key=key)
            
        if self.best_solution is None or self.compare_objective_value(candidate, self.best_solution) < 0:
            self.best_solution = np.copy(candidate)
        
        return self.best_solution


    def compare_objective_value(self, s0, s1):
        v0 = self.objective_fct(s0)
        v1 = self.objective_fct(s1)

        if self.objective == 'min':
            return v0 - v1
        elif self.objective == 'max':
            return v1 - v0
        
        
    def argsort_objective(self):
        if self.objective == 'min':
            return np.argsort([self.objective_fct(s) for s in self.solutions]).ravel()
        elif self.objective == 'max':
            return np.argsort([self.objective_fct(s)for s in self.solutions])[::-1].ravel()
    
    
    def evaluation_count_decorator(self, f, x):
        self.evaluation_count += 1
        return f(x)
    
    
    def random_uniform_in_ranges(self):
        rnd = np.zeros(self.d)
        for i in range(self.d):
            rnd[i] = np.random.uniform(self.range_min[i], self.range_max[i])
        return rnd
    
    def clip_to_ranges(self, x):
        for i in range(self.d):
            x[i] = np.clip(x[i], self.range_min[i], self.range_max[i])
        return x
    
    
    def search(self, objective, objective_fct, T, visualize=False):
        
        if not self.constraints_satisfied():
            return (np.nan, np.nan), np.nan
        
        self.objective = objective
        self.evaluation_count = 0
        self.objective_fct = lambda x: self.evaluation_count_decorator(objective_fct, x)
        self.history = np.zeros((T, self.d))
        self.best_solution = self.random_uniform_in_ranges()
        self.initialize()
        
        t_start = process_time()
        

        if visualize:
            self.visualize_search_step()
            
        for t in range(T):
            self.execute_search_step(t)
            self.history[t] = self.get_best_solution() 

            if visualize:
                self.visualize_search_step(t+1)

        t_end = process_time()

        return (self.best_solution, self.objective_fct(self.best_solution)), t_end-t_start


    def plot_history(self):
        plt.plot([self.objective_fct(s) for s in self.history])
        plt.xlabel('iteration')
        plt.ylabel('objective function value')
        plt.show()


    def initialize(self):
        raise NotImplementedError


    def execute_search_step(self, t):
        raise NotImplementedError


    def visualize_search_step(self, t=0):
        if self.d != 2:
            return
        
        range_min = np.max(self.range_min)
        range_max = np.max(self.range_max)
        
        x = np.linspace(range_min, range_max, 100)
        y = np.linspace(range_min, range_max, 100)
        
        X, Y = np.meshgrid(x, y)
        
        XY = np.array((X, Y)).T
        Z = np.zeros(XY.shape[:-1])
        for i in range(Z.shape[0]):
            for j in range(Z.shape[1]):
                Z[i,j] = self.objective_fct(XY[i,j])
        
        fig = plt.figure(figsize=(8, 8))
        ax = fig.add_subplot(111, aspect='equal')
        
        
        ax.set_xlim([range_min, range_max])
        ax.set_ylim([range_min, range_max])       

        ax.contourf(X, Y, Z, 20, cmap='Greys');
        ax.contour(X, Y, Z, 20, colors='black', linestyles='dotted');
        
        ax.scatter(self.solutions.T[0], self.solutions.T[1], marker='.', c='black')
        ax.scatter(self.best_solution[0], self.best_solution[1], marker='X', s=100, c='red')
        
        savepath = f"images/{self.name}/"
        
        if not os.path.isdir(savepath):
            os.makedirs(savepath)
        
        plt.savefig(os.path.join(savepath, f"{self.name}_{t}.png"))
        plt.close()
        
        
    def generate_gif(self, filename=None):
        if not filename:
            filename = self.name
        
        plot_paths = [f"images/{self.name}/"+file for file in os.listdir(f"images/{self.name}")]
        
        with imageio.get_writer(f"{filename}.gif", mode='I') as writer:
            for filepath in plot_paths:
                image = imageio.imread(filepath)
                writer.append_data(image)

#from .base import BaseSearchAlgorithm
import numpy as np

class BatAlgorithm(BaseSearchAlgorithm):

    def __init__(self, **kwargs):
        super().__init__("bat", **kwargs)

        self.a_init = self.params['a'] # initial loudness of all bats
        self.r_max = self.params['r_max'] # maximum pulse rate of bats
        self.alpha = self.params['alpha'] # loudness decreasing factor
        self.gamma = self.params['gamma'] # pulse rate increasing factor
        self.f_min = self.params['f_min'] # minimum sampled frequency
        self.f_max = self.params['f_max'] # maximum sampled frequency
    
    
    def initialize(self):
        self.solutions = np.zeros(shape=(self.n, self.d))
        for i in range(self.n):
            self.solutions[i] = self.random_uniform_in_ranges()
            
        self.q = np.zeros(self.n)
        self.v = np.zeros((self.n, self.d))
        self.b = np.zeros((self.n, self.d))
            
        self.a = np.repeat(self.a_init, self.n)
        self.r = np.zeros(self.n)
        
        
    def constraints_satisfied(self):
        return self.f_min < self.f_max


    def execute_search_step(self, t):
        self.f = np.random.uniform(self.f_min, self.f_max, self.n)

        for i in range(self.n):
            
            if np.random.uniform(0, 1) < self.r[i]:
                self.b[i] = self.best_solution + np.mean(self.a) * np.random.uniform(-1, 1, self.d)
            else:
                self.v[i] = self.v[i] + (self.solutions[i] - self.best_solution) * self.f[i]
                self.b[i] = self.solutions[i] + self.v[i]
            
            self.b[i] = self.clip_to_ranges(self.b[i])
            
            if self.compare_objective_value(self.b[i], self.solutions[i]) < 0:
                if np.random.uniform(0, 1) < self.a[i]:
                    self.solutions[i] = self.b[i]
                    self.a[i] *= self.alpha
                    self.r[i] = self.r_max * (1-np.exp(-self.gamma * t))

#from .base import BaseSearchAlgorithm
import numpy as np


class BeesAlgorithm(BaseSearchAlgorithm):

    def __init__(self, **kwargs):
        super().__init__("bees", **kwargs)

        self.nb = self.params['nb'] # number of (best) scouts that recruit foragers
        self.ne = self.params['ne'] # number of elite scouts that recruit more
        self.nrb = self.params['nrb'] # number recruited foragers per best scout
        self.nre = self.params['nre'] # number of recruited foragers per elite scout

        self.initial_size = 1.0


    def constraints_satisfied(self):
        return self.ne <= self.nb       


    def initialize(self):
        self.solutions = np.zeros((self.n, self.d))
        self.flower_patch = [None] * self.n
        self.size = [self.initial_size] * self.n

        for i in range(self.n):
            self.initialize_flower_patch(i)


    def execute_search_step(self, t):
        
        self.waggle_dance()

        for i in range(self.nb):
            self.local_search(i)

        for i in range(self.nb, self.n):
            self.global_search(i)


    def initialize_flower_patch(self, i):
        self.solutions[i] = self.create_random_scout()
        self.flower_patch[i] = {'size': self.initial_size}


    def create_random_scout(self):
        return self.random_uniform_in_ranges()


    def create_random_forager(self, i):
        nght = self.flower_patch[i]['size']
        forager = np.random.uniform(-1, 1) * nght + self.solutions[i]
        for j in range(self.d):
            forager[j] = np.clip(forager[j], self.range_min[j], self.range_max[j])
        return forager


    def waggle_dance(self):
        idxs = self.argsort_objective()
        self.solutions = self.solutions[idxs]
        self.flower_patch = np.array(self.flower_patch)[idxs].ravel()
        # recruitment is done in header of local search loop


    def local_search(self, i):
        for j in range(self.nrb if i < self.nb else self.nre):
            forager = self.create_random_forager(i)
            if self.compare_objective_value(forager, self.solutions[i]) < 0:
                self.solutions[i] = forager
                self.initialize_flower_patch(i)


    def global_search(self, i):
        self.initialize_flower_patch(i)
            


class ImprovedBeesAlgorithm(BeesAlgorithm):

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        self.nb = self.params['nb'] # number of (best) scouts that recruit foragers
        self.ne = self.params['ne'] # number of elite scouts that recruit more
        self.nrb = self.params['nrb'] # number recruited foragers per best scout
        self.nre = self.params['nre'] # number of recruited foragers per elite scout
        self.sf = self.params['sf'] # shrinking factor
        self.sl = self.params['sl'] # stagnation limit

        self.initial_size = 1.0
        

    def execute_search_step(self, t):
        self.waggle_dance()

        for i in range(self.nb):
            self.local_search(i)
            self.abandon_sites(i)
            self.shrink_neighborhood(i)

        for i in range(self.nb, self.n):
            self.global_search(i)


    def initialize_flower_patch(self, i):
        self.solutions[i] = self.create_random_scout()
        self.flower_patch[i] = {'size': self.initial_size, 'scnt': self.sl}


    def shrink_neighborhood(self, i):
        self.flower_patch[i]['size'] *= self.sf


    def abandon_sites(self, i):
        if self.flower_patch[i]['scnt'] >  0:
            self.flower_patch[i]['scnt'] -= 1
        else:
            self.initialize_flower_patch(i)

#from .base import BaseSearchAlgorithm
import numpy as np

class FireflyAlgorithm(BaseSearchAlgorithm):

    def __init__(self, **kwargs):
        super().__init__("firefly", **kwargs)

        self.alpha = self.params['alpha'] # neighbor sphere radius
        self.beta_max = self.params['beta_max'] # maximum attractivneness
        self.gamma = self.params['gamma'] # attractiveness descreasing factor


    def initialize(self):
        self.solutions = np.zeros(shape=(self.n, self.d))
        for i in range(self.n):
            self.solutions[i] = self.random_uniform_in_ranges()
            
            
    def execute_search_step(self, t):
        for i in range(self.n):
            for j in range(self.n):

                if self.light_intensity(i) < self.light_intensity(j):
                    diff_ij = (self.solutions[j] - self.solutions[i])
                    r_ij = np.sqrt(np.sum(np.square(diff_ij)))
                    beta_ij = self.beta_max * np.exp(-self.gamma * r_ij**2)
                    self.solutions[i] += beta_ij * diff_ij + self.alpha * np.random.uniform(-0.5, 0.5, self.d)
                    self.clip_to_ranges(self.solutions[i])


    def light_intensity(self, i):
        if self.objective == 'min':
            return 1 / (1e-16+self.objective_fct(self.solutions[i]))
        elif self.objective == 'max':
            return self.objective_fct(self.solutions[i])

#from .base import BaseSearchAlgorithm
import numpy as np

class RandomSamplingAlgorithm(BaseSearchAlgorithm):

    def __init__(self, **kwargs):
        super().__init__("random", **kwargs)

    def initialize(self):
        self.solutions = np.zeros(shape=(self.n, self.d))
        
    def execute_search_step(self, t):
        
        for i in range(self.n):
            self.solutions[i] = self.random_uniform_in_ranges()

import numpy as np
import matplotlib.pyplot as plt

from sklearn.decomposition import PCA
from sklearn.datasets import load_iris

def create_cluster_loss(X, k):
    def cluster_loss(x):
        centers = np.split(x, k)
        dists = np.zeros((len(centers), len(X)))
        for i in range(len(centers)):
            dists[i] = np.sqrt(np.sum(np.square(X-centers[i]), axis=1))
        return np.sum(np.min(dists, axis=0))
    
    return cluster_loss



def plot_clustered_data(X, centers):
    dists = np.zeros((len(centers), len(X)))
    for i in range(len(centers)):
        dists[i] = np.sqrt(np.sum(np.square(X-centers[i]), axis=1))
    respons = np.argmin(dists, axis=0)
    if X.shape[1] > 2:
        pca = PCA(2).fit_transform(np.concatenate([X, centers], axis=0))
        
    X = pca[:-len(centers)]
    centers = pca[-len(centers):]
    
    plt.title('clustered data points')
    plt.scatter(X.T[0], X.T[1], c=respons)
    centers = np.array(centers)
    plt.scatter(centers.T[0], centers.T[1], c='black', marker='X')
    plt.show()


iris_data = load_iris()['data']
iris_labels = load_iris()['target']

plt.title('ground truth iris data set')
iris_data_pca = PCA(2).fit_transform(iris_data)
plt.scatter(iris_data_pca.T[0], iris_data_pca.T[1], c=iris_labels)
plt.show()

true_centers = np.array([np.mean(iris_data[np.where(iris_labels == label)], axis=(0)) for label in set(iris_labels)])
plot_clustered_data(iris_data, true_centers)

objective = 'min'
n = iris_data.shape[0]
k = 3
d_iris = iris_data.shape[1] * k # we concatenate all k cluster centers to one vector, i.e. k times 4 dimensions in iris data set
range_min  = -5.0
range_max = 5.0
T = 200

iris_loss = create_cluster_loss(iris_data, k=k)
iris_loss(true_centers)

bees = BeesAlgorithm(d=d_iris, n=n, range_min=range_min, range_max=range_max,
                     nb=50, ne=20, nrb=5, nre=10, shrink_factor=0.8, stgn_lim=5)

bat = BatAlgorithm(d=d_iris, n=n, range_min=range_min, range_max=range_max,
                   a=0.5, r_max=0.5, alpha=0.9, gamma=0.9, f_min=0.0, f_max=3.0)

firefly = FireflyAlgorithm(d=d_iris, n=n, range_min=range_min, range_max=range_max,
                           alpha=1.0, beta_max=1.0, gamma=0.5)

solution_iris, latency_iris = bees.search(objective, iris_loss, T)
solution_iris_x, solution_iris_y = solution_iris
print(solution_iris)
print(latency_iris)
bees.plot_history()

centers_iris = np.split(solution_iris_x, k)
plot_clustered_data(iris_data, centers_iris)



solution_iris, latency_iris = bat.search(objective, iris_loss, T)
solution_iris_x, solution_iris_y = solution_iris
print(solution_iris)
print(latency_iris)
bat.plot_history()

centers_iris = np.split(solution_iris_x, k)
plot_clustered_data(iris_data, centers_iris)

'''
solution_iris, latency_iris = firefly.search(objective, iris_loss, T)
solution_iris_x, solution_iris_y = solution_iris
print(solution_iris)
print(latency_iris)
firefly.plot_history()

centers_iris = np.split(solution_iris_x, k)
plot_clustered_data(iris_data, centers_iris)
'''