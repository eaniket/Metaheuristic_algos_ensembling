# -*- coding: utf-8 -*-
"""SimulatedAnnealing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ixlhfhex9d7fnvDK79u1j7nkQ-x3aQVt
"""

# !pip install simulated_annealing

from sklearn.model_selection import train_test_split
from sklearn import svm, datasets
from sklearn.metrics import classification_report
from simulated_annealing.optimize import SimulatedAnneal
import numpy as np

# Load the Iris data set
iris = datasets.load_iris()
X = iris.data
y = iris.target
# Split the data into test and train sets                         
X_train, X_test, y_train, y_test = train_test_split(X, y)
# This is the hyperparameter space we'll be searching over
svc_params = {'C':np.logspace(-8, 10, 19, base=2),
              'fit_intercept':[True, False]
             }

# Using a linear SVM classifier             
clf = svm.LinearSVC(max_iter = 1000, dual = False)
# Initialize Simulated Annealing and fit
sa = SimulatedAnneal(clf, svc_params, T=10.0, T_min=0.001, alpha=0.75,
                         verbose=True, max_iter=1000, n_trans=5, max_runtime=300,
                         cv=3, scoring='f1_macro', refit=True)
sa.fit(X_train, y_train)

# Print the best score and the best params
print("Score : ")
print(sa.best_score_, sa.best_params_)
# Use the best estimator to predict classes
optimized_clf = sa.best_estimator_
y_test_pred = optimized_clf.predict(X_test)
print(y_test_pred)
print("Classification report : ")
# Print a report of precision, recall, f1_score
print(classification_report(y_test, y_test_pred))


print("Sklearn metrics")
from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_test_pred)